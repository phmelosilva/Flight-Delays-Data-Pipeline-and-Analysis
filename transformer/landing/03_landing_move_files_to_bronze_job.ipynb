{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ad487a-870e-463e-a62d-9845b50d3269",
   "metadata": {},
   "source": [
    "# 04_landing_move_files_to_bronze_job\n",
    "---\n",
    "Este notebook move os arquivos `parquet` da camada **Stage** para a camada **Bronze**, organizando-os por data de processamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "473df1fa-14ce-4aa6-8e06-09f75e04df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "stage_path = \"/opt/airflow/data-layer/stage\"\n",
    "bronze_path = \"/opt/airflow/data-layer/bronze\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67371547-1cb8-474d-9f7b-f4302f2756a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 00:04:34 [INFO] landing.move_to_bronze | [INFO] Logger inicializado no modo standalone (INFO).\n",
      "2025-11-12 00:04:34 [INFO] spark_helpers | [INFO] SparkSession criada com sucesso: 'MoveStageToBronze' (master=local[*]).\n",
      "2025-11-12 00:04:34 [INFO] landing.move_to_bronze | [Landing][MoveToBronze] SparkSession iniciada.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from transformer.utils.spark_helpers import get_spark_session\n",
    "from transformer.utils.file_io import check_files_in_folder, move_files\n",
    "from transformer.utils.logger import get_logger\n",
    "\n",
    "log = get_logger(\"landing.move_to_bronze\")\n",
    "\n",
    "spark = get_spark_session(\"MoveStageToBronze\")\n",
    "log.info(\"[Landing][MoveToBronze] SparkSession iniciada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71535e0d-1ae6-490e-9f5b-709bfb5ad882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 00:04:06 [INFO] landing.move_to_bronze | [Landing][MoveToBronze] Iniciando job de movimentação de arquivos.\n",
      "2025-11-12 00:04:06 [INFO] file_io | [INFO] Encontrados 3 arquivo(s).\n",
      "2025-11-12 00:04:06 [INFO] file_io | [INFO] Movendo arquivos para '/opt/airflow/data-layer/bronze'.\n",
      "2025-11-12 00:04:06 [INFO] file_io | [INFO] Diretório criado: /opt/airflow/data-layer/bronze/2025-11-12/PARQUET\n",
      "2025-11-12 00:04:06 [INFO] file_io | [INFO] 'airlines.parquet' movido para '/opt/airflow/data-layer/bronze/2025-11-12/PARQUET/airlines.parquet'.\n",
      "2025-11-12 00:04:06 [INFO] file_io | [INFO] 'airports.parquet' movido para '/opt/airflow/data-layer/bronze/2025-11-12/PARQUET/airports.parquet'.\n",
      "2025-11-12 00:04:06 [INFO] file_io | [INFO] 'flights.parquet' movido para '/opt/airflow/data-layer/bronze/2025-11-12/PARQUET/flights.parquet'.\n",
      "2025-11-12 00:04:06 [INFO] file_io | [INFO] Movimentação concluída com sucesso.\n",
      "2025-11-12 00:04:06 [INFO] landing.move_to_bronze | [Landing][MoveToBronze] 3 arquivo(s) movido(s) para bronze/2025-11-12.\n",
      "2025-11-12 00:04:06 [INFO] landing.move_to_bronze | [Landing][MoveToBronze] Job concluído com sucesso.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    log.info(\"[Landing][MoveToBronze] Iniciando job de movimentação de arquivos.\")\n",
    "\n",
    "    parquet_files = check_files_in_folder(stage_path, \"*.parquet\")\n",
    "    if not parquet_files:\n",
    "        raise FileNotFoundError(f\"[Landing][MoveToBronze][ERROR] Nenhum arquivo Parquet encontrado em {stage_path}.\")\n",
    "\n",
    "    processing_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    move_files(\n",
    "        spark=spark,\n",
    "        source_files=parquet_files,\n",
    "        base_dest_path=bronze_path,\n",
    "        processing_date=processing_date,\n",
    "    )\n",
    "\n",
    "    log.info(f\"[Landing][MoveToBronze] {len(parquet_files)} arquivo(s) movido(s) para bronze/{processing_date}.\")\n",
    "    \n",
    "    log.info(\"[Landing][MoveToBronze] Job concluído com sucesso.\")\n",
    "\n",
    "except Exception as e:\n",
    "    log.exception(f\"[Landing][MoveToBronze][ERROR] Falha durante execução: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0cbd60cc-53ef-47f8-8a23-765055cb6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # Comentar essa linha se estiver em debug ou se quiser rodar a célula.\n",
    "path = \"/opt/airflow/data-layer/bronze/2025-11-12/PARQUET/flights.parquet\"\n",
    "\n",
    "df = spark.read.parquet(str(path))\n",
    "df.select(\"ORIGIN_AIRPORT\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a5065fe-0c73-4035-997e-75e545052827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 00:05:20 [INFO] landing.move_to_bronze | [Landing][MoveToBronze] Sessão Spark finalizada.\n"
     ]
    }
   ],
   "source": [
    "# Encerrando a sessão Spark\n",
    "spark.stop()\n",
    "log.info(\"[Landing][MoveToBronze] Sessão Spark finalizada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7617a-c687-4c81-a05d-a4040630dd66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
