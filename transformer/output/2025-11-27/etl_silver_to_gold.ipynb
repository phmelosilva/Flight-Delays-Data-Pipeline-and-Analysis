{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9f4573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:15:45.072811Z",
     "iopub.status.busy": "2025-11-27T03:15:45.070461Z",
     "iopub.status.idle": "2025-11-27T03:15:45.084737Z",
     "shell.execute_reply": "2025-11-27T03:15:45.081673Z"
    },
    "papermill": {
     "duration": 0.042022,
     "end_time": "2025-11-27T03:15:45.087789",
     "exception": false,
     "start_time": "2025-11-27T03:15:45.045767",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run_mode = \"latest\"\n",
    "run_date = None\n",
    "silver_path = \"/opt/airflow/data-layer/silver\"\n",
    "gold_path = \"/opt/airflow/data-layer/gold\"\n",
    "aggregated_name = \"flights_aggregated.parquet\"\n",
    "postgres_conn_id = \"dw\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d86d33-181e-40d2-a0fe-90c4548220af",
   "metadata": {
    "papermill": {
     "duration": 0.027629,
     "end_time": "2025-11-27T03:15:45.134235",
     "exception": false,
     "start_time": "2025-11-27T03:15:45.106606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# etl_silver_to_gold\n",
    "---\n",
    "Este notebook executa o processo `ETL` que transfere os dados da camada **Silver** para a **Gold**, englobando normalização, movimentação dos arquivos e carga dos dados no *PostgreSQL*, dando finalidade ao pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ebf692-724f-4183-9db8-f827aa80f95c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:15:45.191280Z",
     "iopub.status.busy": "2025-11-27T03:15:45.190797Z",
     "iopub.status.idle": "2025-11-27T03:15:45.203350Z",
     "shell.execute_reply": "2025-11-27T03:15:45.198273Z"
    },
    "papermill": {
     "duration": 0.044313,
     "end_time": "2025-11-27T03:15:45.206295",
     "exception": false,
     "start_time": "2025-11-27T03:15:45.161982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "run_mode = \"latest\"\n",
    "run_date = None\n",
    "\n",
    "silver_path = \"/opt/airflow/data-layer/silver\"\n",
    "gold_path = \"/opt/airflow/data-layer/gold\"\n",
    "\n",
    "aggregated_name = \"flights_aggregated.parquet\"\n",
    "postgres_conn_id = \"AIRFLOW_VAR_POSTGRES_CONN_ID\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90039f5-ae72-4d8b-97e4-0ba25c56ec40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:15:45.264816Z",
     "iopub.status.busy": "2025-11-27T03:15:45.264260Z",
     "iopub.status.idle": "2025-11-27T03:15:45.900973Z",
     "shell.execute_reply": "2025-11-27T03:15:45.898730Z"
    },
    "papermill": {
     "duration": 0.66966,
     "end_time": "2025-11-27T03:15:45.902227",
     "exception": false,
     "start_time": "2025-11-27T03:15:45.232567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from transformer.utils.file_io import find_partition\n",
    "from transformer.utils.logger import get_logger\n",
    "from transformer.utils.spark_helpers import get_spark_session, load_to_postgres, read_from_postgres\n",
    "from transformer.utils.postgre_helpers import assert_table_rowcount\n",
    "from transformer.utils.quality_gates_gold import run_quality_gates_gold\n",
    "\n",
    "from pyspark.sql import DataFrame, functions as F\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cdbbf0-e811-40f5-8a53-c08b22d520e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.026352,
     "end_time": "2025-11-27T03:15:45.948069",
     "exception": false,
     "start_time": "2025-11-27T03:15:45.921717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Job 1: build_and_load_gold_star_schema\n",
    "\n",
    "Este job realiza a construção do esquema estrela da camada **Gold**, materializando as tabelas dimensionais e fato a partir da tabela `silver_flights`, salva os dados em formato `parquet` na camada **Gold** e carregando os dados no *PostgreSQL* de acordo com o ddl da camada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97709fef-fbb7-492c-9ebb-01d905ec42f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:15:46.004103Z",
     "iopub.status.busy": "2025-11-27T03:15:46.003468Z",
     "iopub.status.idle": "2025-11-27T03:16:02.684655Z",
     "shell.execute_reply": "2025-11-27T03:16:02.665593Z"
    },
    "papermill": {
     "duration": 16.719712,
     "end_time": "2025-11-27T03:16:02.692268",
     "exception": false,
     "start_time": "2025-11-27T03:15:45.972556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9401ddb0-38e6-443d-8c08-8d76ec8d311a;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.postgresql#postgresql;42.7.3 in central\n",
      "\tfound org.checkerframework#checker-qual;3.42.0 in central\n",
      ":: resolution report :: resolve 466ms :: artifacts dl 22ms\n",
      "\t:: modules in use:\n",
      "\torg.checkerframework#checker-qual;3.42.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.7.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9401ddb0-38e6-443d-8c08-8d76ec8d311a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/25ms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/27 03:15:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:02 [INFO] spark_helpers: [INFO] SparkSession criada: 'BuildLoadGoldStarSchema' (master=local[*]).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:02 [INFO] build_and_load_gold_star_schema: [BuildLoad] SparkSession iniciada.\n"
     ]
    }
   ],
   "source": [
    "log = get_logger(\"build_and_load_gold_star_schema\")\n",
    "\n",
    "spark = get_spark_session(\"BuildLoadGoldStarSchema\")\n",
    "log.info(\"[BuildLoad] SparkSession iniciada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228db41-f5f1-4fe7-87f6-60f1faacfadf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.037783,
     "end_time": "2025-11-27T03:16:02.777783",
     "exception": false,
     "start_time": "2025-11-27T03:16:02.740000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Definindo função de materialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e3b960-7ef3-4f87-a5bb-62ffed79ceba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:16:02.860167Z",
     "iopub.status.busy": "2025-11-27T03:16:02.858014Z",
     "iopub.status.idle": "2025-11-27T03:16:02.896481Z",
     "shell.execute_reply": "2025-11-27T03:16:02.895084Z"
    },
    "papermill": {
     "duration": 0.089969,
     "end_time": "2025-11-27T03:16:02.900065",
     "exception": false,
     "start_time": "2025-11-27T03:16:02.810096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def materialize_gold_layer(df: DataFrame) -> dict[str, DataFrame]:\n",
    "    \"\"\"\n",
    "    Materializa as tabelas dimensionais e fato da camada gold a partir do DataFrame agregado.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame consolidado da camada gold.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, DataFrame]: DataFrames correspondentes a dim_air, dim_apt, dim_dat e fat_flt.\n",
    "    \"\"\"\n",
    "    # Feriados federais nos EUA em 2015 (UTC)\n",
    "    us_holidays_2015 = [\n",
    "        \"2015-01-01\",\n",
    "        \"2015-01-19\",\n",
    "        \"2015-02-16\",\n",
    "        \"2015-05-25\",\n",
    "        \"2015-07-04\",\n",
    "        \"2015-09-07\",\n",
    "        \"2015-10-12\",\n",
    "        \"2015-11-11\",\n",
    "        \"2015-11-26\",\n",
    "        \"2015-12-25\",\n",
    "    ]\n",
    "    holidays_df = (\n",
    "        spark.createDataFrame([(d,) for d in us_holidays_2015], [\"holiday_date\"])\n",
    "            .withColumn(\"holiday_date\", F.col(\"holiday_date\").cast(DateType()))\n",
    "    )\n",
    "    \n",
    "    log.info(\"[Materialize] Iniciando materialização da camada gold.\")\n",
    "\n",
    "    # dim_air\n",
    "    log.info(\"[Materialize] Materializando 'dim_air'.\")\n",
    "    dim_air = (\n",
    "        df.select(\"airline_iata_code\", \"airline_name\")\n",
    "            .distinct()\n",
    "            .withColumn(\"airline_id\", F.monotonically_increasing_id())\n",
    "            .select(\"airline_id\", \"airline_iata_code\", \"airline_name\")\n",
    "    )\n",
    "\n",
    "    # dim_apt\n",
    "    log.info(\"[Materialize] Materializando 'dim_apt'.\")\n",
    "    dim_apt = (\n",
    "        df.select(\n",
    "            F.col(\"origin_airport_iata_code\").alias(\"airport_iata_code\"),\n",
    "            F.col(\"origin_airport_name\").alias(\"airport_name\"),\n",
    "            F.col(\"origin_city\").alias(\"city_name\"),\n",
    "            F.col(\"origin_state\").alias(\"state_code\"),\n",
    "            F.col(\"origin_latitude\").alias(\"latitude\"),\n",
    "            F.col(\"origin_longitude\").alias(\"longitude\")\n",
    "        )\n",
    "            .union(\n",
    "                df.select(\n",
    "                    F.col(\"dest_airport_iata_code\").alias(\"airport_iata_code\"),\n",
    "                    F.col(\"dest_airport_name\").alias(\"airport_name\"),\n",
    "                    F.col(\"dest_city\").alias(\"city_name\"),\n",
    "                    F.col(\"dest_state\").alias(\"state_code\"),\n",
    "                    F.col(\"dest_latitude\").alias(\"latitude\"),\n",
    "                    F.col(\"dest_longitude\").alias(\"longitude\")\n",
    "                )\n",
    "            )\n",
    "            .distinct()\n",
    "            .withColumn(\"airport_id\", F.monotonically_increasing_id())\n",
    "            .select(\"airport_id\", \"airport_iata_code\", \"airport_name\", \"city_name\",\n",
    "                    \"state_code\", \"latitude\", \"longitude\")\n",
    "    )\n",
    "\n",
    "    # dim_dat\n",
    "    log.info(\"[Materialize] Materializando 'dim_dat'.\")\n",
    "    dim_dat = (\n",
    "        df.select(F.col(\"flight_date\").alias(\"full_date\"))\n",
    "            .distinct()\n",
    "            .withColumn(\"year\", F.year(\"full_date\"))\n",
    "            .withColumn(\"month\", F.month(\"full_date\"))\n",
    "            .withColumn(\"day\", F.dayofmonth(\"full_date\"))\n",
    "            .withColumn(\"day_of_week\", F.dayofweek(\"full_date\"))\n",
    "            .withColumn(\"quarter\", F.quarter(\"full_date\"))\n",
    "            # Augmentation de feriado\n",
    "            .join(holidays_df, F.col(\"full_date\") == F.col(\"holiday_date\"), \"left\")\n",
    "            .withColumn(\"is_holiday\", F.when(F.col(\"holiday_date\").isNotNull(), F.lit(True)).otherwise(F.lit(False)))\n",
    "            .drop(\"holiday_date\")\n",
    "            # Fim do augmentation de feriado\n",
    "            .select(\"full_date\", \"year\", \"month\", \"day\", \"day_of_week\", \"quarter\", \"is_holiday\")\n",
    "    )\n",
    "\n",
    "    # fat_flt\n",
    "    log.info(\"[Materialize] Materializando 'fat_flt'.\")\n",
    "    fat_flt = (\n",
    "        df.withColumn(\"flight_id\", F.monotonically_increasing_id())\n",
    "            .withColumnRenamed(\"flight_date\", \"full_date\")\n",
    "            .select(\n",
    "                \"flight_id\", \"full_date\", \"airline_iata_code\",\n",
    "                \"origin_airport_iata_code\", \"dest_airport_iata_code\",\n",
    "                \"distance\",\n",
    "                \"air_time\", \"elapsed_time\", \"scheduled_time\",\n",
    "                \"taxi_out\", \"taxi_in\",\n",
    "                \"departure_delay\", \"arrival_delay\", \"air_system_delay\", \n",
    "                \"security_delay\", \"airline_delay\", \"late_aircraft_delay\", \"weather_delay\"\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # Joins para adicionar fk's\n",
    "    log.info(\"[Materialize] Adicionando fk's na 'fat_flt'.\")\n",
    "    fat_flt = (\n",
    "        fat_flt\n",
    "            .join(dim_air, on=\"airline_iata_code\", how=\"left\")\n",
    "            .join(dim_apt.select(\n",
    "                F.col(\"airport_id\").alias(\"origin_airport_id\"),\n",
    "                F.col(\"airport_iata_code\").alias(\"origin_airport_iata_code\")\n",
    "            ), on=\"origin_airport_iata_code\", how=\"left\")\n",
    "            .join(dim_apt.select(\n",
    "                F.col(\"airport_id\").alias(\"dest_airport_id\"),\n",
    "                F.col(\"airport_iata_code\").alias(\"dest_airport_iata_code\")\n",
    "            ), on=\"dest_airport_iata_code\", how=\"left\")\n",
    "            .select(\n",
    "                \"flight_id\", \"full_date\", \"airline_id\", \"origin_airport_id\", \"dest_airport_id\",\n",
    "                \"distance\", \"air_time\", \"elapsed_time\", \"scheduled_time\", \"taxi_out\",\n",
    "                \"taxi_in\", \"departure_delay\", \"arrival_delay\",\n",
    "                \"air_system_delay\", \"security_delay\", \"airline_delay\",\n",
    "                \"late_aircraft_delay\", \"weather_delay\"\n",
    "            )\n",
    "    )\n",
    "\n",
    "    log.info(\"[Materialize] Materialização concluída.\")\n",
    "    \n",
    "    return {\n",
    "        \"dim_air\": dim_air,\n",
    "        \"dim_apt\": dim_apt,\n",
    "        \"dim_dat\": dim_dat,\n",
    "        \"fat_flt\": fat_flt\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b51023-792b-4e73-908f-dcd02c7cac2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.053594,
     "end_time": "2025-11-27T03:16:02.982664",
     "exception": false,
     "start_time": "2025-11-27T03:16:02.929070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Runner para o job `build_and_load_gold_star_schema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cedf860a-e188-4e9d-8f11-b6875777dbae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:16:03.071679Z",
     "iopub.status.busy": "2025-11-27T03:16:03.071078Z",
     "iopub.status.idle": "2025-11-27T03:35:59.899283Z",
     "shell.execute_reply": "2025-11-27T03:35:59.867349Z"
    },
    "papermill": {
     "duration": 1196.896655,
     "end_time": "2025-11-27T03:35:59.923570",
     "exception": false,
     "start_time": "2025-11-27T03:16:03.026915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:03 [INFO] build_and_load_gold_star_schema: [BuildLoad] Iniciando job de materialização da gold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:03 [INFO] spark_helpers: [READ] Iniciando leitura de 'silver.silver_flights'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:03 [WARN] spark_helpers: [WARN] Airflow indisponível, usando variáveis de ambiente para conexão PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 0) / 1]\r",
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "2025-11-27 03:16:22 [INFO] spark_helpers: [READ] Leitura concluída: 'silver.silver_flights'. Linhas: 5208259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:22 [INFO] build_and_load_gold_star_schema: [BuildLoad] Datasets carregado a partir do PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:24 [INFO] build_and_load_gold_star_schema: [Materialize] Iniciando materialização da camada gold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:24 [INFO] build_and_load_gold_star_schema: [Materialize] Materializando 'dim_air'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:24 [INFO] build_and_load_gold_star_schema: [Materialize] Materializando 'dim_apt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:24 [INFO] build_and_load_gold_star_schema: [Materialize] Materializando 'dim_dat'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:25 [INFO] build_and_load_gold_star_schema: [Materialize] Materializando 'fat_flt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:25 [INFO] build_and_load_gold_star_schema: [Materialize] Adicionando fk's na 'fat_flt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:25 [INFO] build_and_load_gold_star_schema: [Materialize] Materialização concluída.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:25 [INFO] build_and_load_gold_star_schema: [BuildLoad] Iniciando quality gate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:16:25 [INFO] quality_gates_gold: [Quality][Gold] Iniciando validações.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "2025-11-27 03:19:48 [INFO] quality_gates_gold: [Quality][Gold]      _check_unique: 'airline_iata_code' OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "2025-11-27 03:22:55 [INFO] quality_gates_gold: [Quality][Gold]      _check_unique: 'airport_iata_code' OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:>                 (0 + 1) / 1][Stage 28:>                 (0 + 7) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:>                 (0 + 1) / 1][Stage 28:===============>  (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 32:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "2025-11-27 03:23:11 [INFO] quality_gates_gold: [Quality][Gold]      _check_unique: 'full_date' OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 50:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 50:=====================>                                    (3 + 5) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:25:37 [INFO] quality_gates_gold: [Quality][Gold]      _check_unique: 'flight_id' OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:25:38 [INFO] quality_gates_gold: [Quality][Gold]      _check_no_nulls: fat_flt OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 66:==============>                                           (2 + 6) / 8]\r",
      "\r",
      "[Stage 66:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "2025-11-27 03:25:41 [INFO] quality_gates_gold: [Quality][Gold]           _check_fk_integrity: [fat_flt] 'airline_id' <-> 'dim_air.airline_id' OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:25:43 [INFO] quality_gates_gold: [Quality][Gold]           _check_fk_integrity: [fat_flt] 'origin_airport_id' <-> 'dim_apt.airport_id' OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:25:45 [INFO] quality_gates_gold: [Quality][Gold]           _check_fk_integrity: [fat_flt] 'dest_airport_id' <-> 'dim_apt.airport_id' OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 93:=======>                                                  (1 + 7) / 8]\r",
      "\r",
      "[Stage 93:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "2025-11-27 03:25:47 [INFO] quality_gates_gold: [Quality][Gold]           _check_fk_integrity: [fat_flt] 'full_date' <-> 'dim_dat.full_date' OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:25:47 [INFO] quality_gates_gold: [Quality][Gold] Todas as validações concluídas com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:25:47 [INFO] build_and_load_gold_star_schema: [BuildLoad] Quality gate concluído com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:25:47 [INFO] build_and_load_gold_star_schema: [BuildLoad] Iniciando escrita dos arquivos na camada gold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 98:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 100:>                                                        (0 + 8) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 102:>                                                        (0 + 8) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 104:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 104:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 104:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 104:============================>                            (4 + 4) / 8]\r",
      "\r",
      "[Stage 104:===================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 104:==========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 104:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:19 [INFO] build_and_load_gold_star_schema: [BuildLoad] Escrita concluída com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:19 [INFO] build_and_load_gold_star_schema: [BuildLoad] Iniciando carga da gold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:19 [INFO] build_and_load_gold_star_schema: [BuildLoad] Carregando tabela: gold.dim_air.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:19 [WARN] spark_helpers: [WARN] Airflow indisponível, usando variáveis de ambiente para conexão PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:19 [INFO] spark_helpers: [LOAD] Limpando tabela 'gold.dim_air' (TRUNCATE).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 111:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 111:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "2025-11-27 03:26:24 [INFO] spark_helpers: [LOAD] Carga concluída em 'gold.dim_air' (modo=append).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:24 [INFO] build_and_load_gold_star_schema: [BuildLoad] Tabela 'gold.dim_air' carregada. Validando integridade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:24 [INFO] postgres_helpers: [AssertRowCount] Validando contagem da tabela 'gold.dim_air'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:24 [INFO] postgres_helpers: [AssertRowCount] Esperado: 14 | Encontrado: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:24 [INFO] postgres_helpers: [AssertRowCount] Validação concluída com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:24 [INFO] build_and_load_gold_star_schema: [BuildLoad] Validação concluída com sucesso: gold.dim_air.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:24 [INFO] build_and_load_gold_star_schema: [BuildLoad] Carregando tabela: gold.dim_apt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:24 [WARN] spark_helpers: [WARN] Airflow indisponível, usando variáveis de ambiente para conexão PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:24 [INFO] spark_helpers: [LOAD] Limpando tabela 'gold.dim_apt' (TRUNCATE).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 118:=====================>                                   (3 + 5) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:27 [INFO] spark_helpers: [LOAD] Carga concluída em 'gold.dim_apt' (modo=append).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:27 [INFO] build_and_load_gold_star_schema: [BuildLoad] Tabela 'gold.dim_apt' carregada. Validando integridade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:27 [INFO] postgres_helpers: [AssertRowCount] Validando contagem da tabela 'gold.dim_apt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:27 [INFO] postgres_helpers: [AssertRowCount] Esperado: 322 | Encontrado: 322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:27 [INFO] postgres_helpers: [AssertRowCount] Validação concluída com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:27 [INFO] build_and_load_gold_star_schema: [BuildLoad] Validação concluída com sucesso: gold.dim_apt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:27 [INFO] build_and_load_gold_star_schema: [BuildLoad] Carregando tabela: gold.dim_dat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:28 [WARN] spark_helpers: [WARN] Airflow indisponível, usando variáveis de ambiente para conexão PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:28 [INFO] spark_helpers: [LOAD] Limpando tabela 'gold.dim_dat' (TRUNCATE).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 125:============================>                            (4 + 4) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:30 [INFO] spark_helpers: [LOAD] Carga concluída em 'gold.dim_dat' (modo=append).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:30 [INFO] build_and_load_gold_star_schema: [BuildLoad] Tabela 'gold.dim_dat' carregada. Validando integridade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:30 [INFO] postgres_helpers: [AssertRowCount] Validando contagem da tabela 'gold.dim_dat'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:30 [INFO] postgres_helpers: [AssertRowCount] Esperado: 334 | Encontrado: 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:30 [INFO] postgres_helpers: [AssertRowCount] Validação concluída com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:30 [INFO] build_and_load_gold_star_schema: [BuildLoad] Validação concluída com sucesso: gold.dim_dat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:30 [INFO] build_and_load_gold_star_schema: [BuildLoad] Carregando tabela: gold.fat_flt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:31 [WARN] spark_helpers: [WARN] Airflow indisponível, usando variáveis de ambiente para conexão PostgreSQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:26:31 [INFO] spark_helpers: [LOAD] Limpando tabela 'gold.fat_flt' (TRUNCATE).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:==============>                                          (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:=====================>                                   (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:===================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:==========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:==========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:35:32 [INFO] spark_helpers: [LOAD] Carga concluída em 'gold.fat_flt' (modo=append).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:35:32 [INFO] build_and_load_gold_star_schema: [BuildLoad] Tabela 'gold.fat_flt' carregada. Validando integridade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:35:32 [INFO] postgres_helpers: [AssertRowCount] Validando contagem da tabela 'gold.fat_flt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:35:59 [INFO] postgres_helpers: [AssertRowCount] Esperado: 5,208,259 | Encontrado: 5,208,259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:35:59 [INFO] postgres_helpers: [AssertRowCount] Validação concluída com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:35:59 [INFO] build_and_load_gold_star_schema: [BuildLoad] Validação concluída com sucesso: gold.fat_flt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:35:59 [INFO] build_and_load_gold_star_schema: [BuildLoad] Carga de todas as tabelas concluída com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:35:59 [INFO] build_and_load_gold_star_schema: [BuildLoad] Job de materialização da gold encerrado.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    log.info(\"[BuildLoad] Iniciando job de materialização da gold.\")\n",
    "\n",
    "    df = read_from_postgres(\n",
    "        spark=spark,\n",
    "        db_conn_id=postgres_conn_id,\n",
    "        table_name=\"silver.silver_flights\",\n",
    "    )\n",
    "\n",
    "    log.info(f\"[BuildLoad] Datasets carregado a partir do PostgreSQL.\")\n",
    "\n",
    "    # Materializando\n",
    "    tables = materialize_gold_layer(df)\n",
    "    dim_air = tables[\"dim_air\"]\n",
    "    dim_apt = tables[\"dim_apt\"]\n",
    "    dim_dat = tables[\"dim_dat\"]\n",
    "    fat_flt = tables[\"fat_flt\"]\n",
    "\n",
    "    # Executa quality gate\n",
    "    log.info(\"[BuildLoad] Iniciando quality gate.\")\n",
    "    run_quality_gates_gold(\n",
    "        dim_air=dim_air,\n",
    "        dim_apt=dim_apt,\n",
    "        dim_dat=dim_dat,\n",
    "        fat_flt=fat_flt\n",
    "    )\n",
    "    log.info(\"[BuildLoad] Quality gate concluído com sucesso.\")\n",
    "\n",
    "    # Define partição de saída\n",
    "    processing_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    output_dir = Path(gold_path) / processing_date / \"PARQUET\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Escreve os arquivos na gold (para debug)\n",
    "    log.info(\"[BuildLoad] Iniciando escrita dos arquivos na camada gold.\")\n",
    "\n",
    "    dim_air.write.mode(\"overwrite\").parquet(str(output_dir / \"dim_air.parquet\"))\n",
    "    dim_apt.write.mode(\"overwrite\").parquet(str(output_dir / \"dim_apt.parquet\"))\n",
    "    dim_dat.write.mode(\"overwrite\").parquet(str(output_dir / \"dim_dat.parquet\"))\n",
    "    fat_flt.write.mode(\"overwrite\").parquet(str(output_dir / \"fat_flt.parquet\"))\n",
    "\n",
    "    log.info(\"[BuildLoad] Escrita concluída com sucesso.\")\n",
    "\n",
    "    log.info(\"[BuildLoad] Iniciando carga da gold.\")\n",
    "\n",
    "    tables = {\n",
    "        \"dim_air\": dim_air,\n",
    "        \"dim_apt\": dim_apt,\n",
    "        \"dim_dat\": dim_dat,\n",
    "        \"fat_flt\": fat_flt,\n",
    "    }\n",
    "\n",
    "    # Carga no PostgreSQL e validação\n",
    "    for table_name, df in tables.items():\n",
    "        full_table_name = f\"gold.{table_name}\"\n",
    "\n",
    "        log.info(f\"[BuildLoad] Carregando tabela: {full_table_name}.\")\n",
    "        expected_count = df.count()\n",
    "\n",
    "        # Carga no PostgreSQL\n",
    "        load_to_postgres(\n",
    "            df=df,\n",
    "            db_conn_id=postgres_conn_id,\n",
    "            table_name=full_table_name,\n",
    "            mode=\"overwrite\"\n",
    "        )\n",
    "\n",
    "        log.info(f\"[BuildLoad] Tabela '{full_table_name}' carregada. Validando integridade.\")\n",
    "\n",
    "        # Validação (fallback se falhar)\n",
    "        try:\n",
    "            assert_table_rowcount(\n",
    "                db_conn_id=postgres_conn_id,\n",
    "                table_name=full_table_name,\n",
    "                expected_count=expected_count,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            log.error(f\"[BuildLoad][ERROR] Validação falhou para '{full_table_name}'. Limpando tabela.\")\n",
    "\n",
    "            import psycopg2\n",
    "\n",
    "            with psycopg2.connect(\n",
    "                host=os.getenv(\"DB_HOST\", \"localhost\"),\n",
    "                dbname=os.getenv(\"DB_NAME\", \"postgres\"),\n",
    "                user=os.getenv(\"DB_USER\", \"postgres\"),\n",
    "                password=os.getenv(\"DB_PASSWORD\", \"postgres\"),\n",
    "            ) as conn_pg:\n",
    "                with conn_pg.cursor() as cur:\n",
    "                    cur.execute(f\"TRUNCATE TABLE {full_table_name} CASCADE;\")\n",
    "                    conn_pg.commit()\n",
    "\n",
    "            raise ValueError(f\"[BuildLoad][ERROR] Falha na validação da tabela '{full_table_name}'.\") from e\n",
    "\n",
    "        log.info(f\"[BuildLoad] Validação concluída com sucesso: {full_table_name}.\")\n",
    "\n",
    "    log.info(\"[BuildLoad] Carga de todas as tabelas concluída com sucesso.\") \n",
    "\n",
    "except Exception as e:\n",
    "    log.exception(f\"[BuildLoad][ERROR] Falha na construção do esquema estrela: {e}.\")\n",
    "    raise\n",
    "\n",
    "finally:\n",
    "    log.info(\"[BuildLoad] Job de materialização da gold encerrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be8a5123-d9eb-4353-84ac-3fedeed12803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:36:00.077530Z",
     "iopub.status.busy": "2025-11-27T03:36:00.047350Z",
     "iopub.status.idle": "2025-11-27T03:36:00.260293Z",
     "shell.execute_reply": "2025-11-27T03:36:00.258304Z"
    },
    "papermill": {
     "duration": 0.288908,
     "end_time": "2025-11-27T03:36:00.261474",
     "exception": false,
     "start_time": "2025-11-27T03:35:59.972566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # Comentar essa linha se estiver em debug ou se quiser rodar a célula.\n",
    "\n",
    "# Verifica arquivos\n",
    "\n",
    "df_show = {\n",
    "    \"dim_air\": dim_air,\n",
    "    \"dim_apt\": dim_apt,\n",
    "    \"dim_dat\": dim_dat,\n",
    "    \"fat_flt\": fat_flt\n",
    "}\n",
    "\n",
    "for name, d in df_show.items():\n",
    "    print(f\"\\n{name}\\n\")\n",
    "    d.printSchema()\n",
    "    d.limit(1).show(truncate=True)\n",
    "\n",
    "# Verifica tabelas\n",
    "\n",
    "jdbc_url = f\"jdbc:postgresql://{os.getenv('DB_HOST', 'localhost')}:{os.getenv('DB_PORT', '5432')}/{os.getenv('DB_NAME', 'postgres')}\"\n",
    "connection_properties = {\n",
    "    \"user\": os.getenv(\"DB_USER\", \"postgres\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\", \"postgres\"),\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "}\n",
    "\n",
    "tables_to_check = [\"dim_air\", \"dim_apt\", \"dim_dat\"]\n",
    "for tbl in tables_to_check:\n",
    "    print(f\"\\n gold.{tbl} \\n\")\n",
    "    df_check = spark.read.jdbc(url=jdbc_url, table=f\"gold.{tbl}\", properties=connection_properties)\n",
    "    df_check.limit(1).show(truncate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c38424-aa86-46e4-8f6e-65e0e532c1c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T03:36:00.304157Z",
     "iopub.status.busy": "2025-11-27T03:36:00.303559Z",
     "iopub.status.idle": "2025-11-27T03:36:01.053380Z",
     "shell.execute_reply": "2025-11-27T03:36:01.051969Z"
    },
    "papermill": {
     "duration": 0.77911,
     "end_time": "2025-11-27T03:36:01.055962",
     "exception": false,
     "start_time": "2025-11-27T03:36:00.276852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 03:36:01 [INFO] build_and_load_gold_star_schema: [BuildLoad] Sessão Spark finalizada.\n"
     ]
    }
   ],
   "source": [
    "# Encerrando a sessão do Spark.\n",
    "spark.stop()\n",
    "log.info(\"[BuildLoad] Sessão Spark finalizada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b070f4-6652-4d0c-96cf-5cb8f77ac23b",
   "metadata": {
    "papermill": {
     "duration": 0.029244,
     "end_time": "2025-11-27T03:36:01.099312",
     "exception": false,
     "start_time": "2025-11-27T03:36:01.070068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1223.250011,
   "end_time": "2025-11-27T03:36:03.975800",
   "environment_variables": {},
   "exception": null,
   "input_path": "/opt/airflow/transformer/etl_silver_to_gold.ipynb",
   "output_path": "/opt/airflow/transformer/output/2025-11-27/etl_silver_to_gold.ipynb",
   "parameters": {
    "aggregated_name": "flights_aggregated.parquet",
    "gold_path": "/opt/airflow/data-layer/gold",
    "postgres_conn_id": "dw",
    "run_date": null,
    "run_mode": "latest",
    "silver_path": "/opt/airflow/data-layer/silver"
   },
   "start_time": "2025-11-27T03:15:40.725789",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}