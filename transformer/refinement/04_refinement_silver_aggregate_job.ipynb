{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c548bac2-07ef-4266-a542-a0ef16bcc58b",
   "metadata": {},
   "source": [
    "# 04_refinement_silver_aggregate_job\n",
    "---\n",
    "Este notebook realiza a agregação da camada **Silver**, unindo os datasets já tratados de `flights`, `airlines` e `airports` em um único dataset consolidado `flights_aggregated.parquet`, conforme o `DDL` da camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6ade78-3c26-45d5-9b80-c1e82e707518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "run_mode = \"latest\"\n",
    "run_date = None\n",
    "\n",
    "silver_path = \"/opt/airflow/data-layer/silver\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dab77ca-ee51-4c1e-a1c8-402404d42379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 23:08:29 [INFO] refinement.silver_aggregate | [INFO] Logger inicializado no modo standalone (INFO).\n",
      "2025-11-13 23:08:29 [INFO] spark_helpers | [INFO] SparkSession criada com sucesso: 'RefinementSilverAggregate' (master=local[*]).\n",
      "2025-11-13 23:08:29 [INFO] refinement.silver_aggregate | [Refinement][Aggregate] Sessão Spark iniciada.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pyspark.sql import DataFrame, functions as F\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "from transformer.utils.spark_helpers import get_spark_session\n",
    "from transformer.utils.file_io import find_partition\n",
    "from transformer.validation.quality_gates_silver_aggregated import run_quality_gates_silver_aggregated\n",
    "from transformer.utils.logger import get_logger\n",
    "\n",
    "log = get_logger(\"refinement.silver_aggregate\")\n",
    "\n",
    "spark = get_spark_session(\"RefinementSilverAggregate\")\n",
    "log.info(\"[Refinement][Aggregate] Sessão Spark iniciada.\")\n",
    "\n",
    "# Ajustes performance\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a8e38a-fd69-4d1c-8255-cfb4e38dba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregated_flights_df(\n",
    "    flights_silver_df: DataFrame,\n",
    "    airlines_silver_df: DataFrame,\n",
    "    airports_silver_df: DataFrame,\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Constrói o DataFrame agregado da camada Silver (flights_aggregated), unindo:\n",
    "        - flights_pre_join.parquet\n",
    "        - airlines.parquet\n",
    "        - airports.parquet\n",
    "\n",
    "    Args:\n",
    "        flights_silver_df (DataFrame): Dataset de voos já transformado (pré-join).\n",
    "        airlines_silver_df (DataFrame): Dataset transformado de companhias aéreas.\n",
    "        airports_silver_df (DataFrame): Dataset transformado de aeroportos.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Dataset consolidado no formato final da camada Silver.\n",
    "    \"\"\"\n",
    "\n",
    "    log.info(\"[Refinement][Aggregate] Iniciando agregação dos datasets Silver.\")\n",
    "\n",
    "    # Detecta coluna de companhia aérea no dataset 'flights'\n",
    "    if \"airline_iata_code\" in flights_silver_df.columns:\n",
    "        airline_col = \"airline_iata_code\"\n",
    "    elif \"airline\" in flights_silver_df.columns:\n",
    "        airline_col = \"airline\"\n",
    "    else:\n",
    "        raise KeyError(\"Nenhuma coluna de companhia aérea encontrada no dataset flights.\")\n",
    "\n",
    "    # Detecta colunas de origem e destino no dataset 'flights'\n",
    "    if \"origin_airport_iata_code\" in flights_silver_df.columns:\n",
    "        origin_col = \"origin_airport_iata_code\"\n",
    "    elif \"origin_airport\" in flights_silver_df.columns:\n",
    "        origin_col = \"origin_airport\"\n",
    "    else:\n",
    "        raise KeyError(\"Coluna de aeroporto de origem não encontrada.\")\n",
    "\n",
    "    if \"dest_airport_iata_code\" in flights_silver_df.columns:\n",
    "        dest_col = \"dest_airport_iata_code\"\n",
    "    elif \"destination_airport\" in flights_silver_df.columns:\n",
    "        dest_col = \"destination_airport\"\n",
    "    else:\n",
    "        raise KeyError(\"Coluna de aeroporto de destino não encontrada.\")\n",
    "\n",
    "    # Join com airlines\n",
    "    df_joined = flights_silver_df.join(\n",
    "        airlines_silver_df,\n",
    "        flights_silver_df[airline_col] == airlines_silver_df[\"airline_iata_code\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # Seleciona campos para aeroportos de origem\n",
    "    df_origin = (\n",
    "        airports_silver_df.select(\n",
    "            F.col(\"airport_iata_code\").alias(\"origin_airport_iata_code\"),\n",
    "            F.col(\"airport_name\").alias(\"origin_airport_name\"),\n",
    "            F.col(\"city\").alias(\"origin_city\"),\n",
    "            F.col(\"state\").alias(\"origin_state\"),\n",
    "            F.col(\"latitude\").alias(\"origin_latitude\"),\n",
    "            F.col(\"longitude\").alias(\"origin_longitude\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Seleciona campos para aeroportos de destino\n",
    "    df_dest = (\n",
    "        airports_silver_df.select(\n",
    "            F.col(\"airport_iata_code\").alias(\"dest_airport_iata_code\"),\n",
    "            F.col(\"airport_name\").alias(\"dest_airport_name\"),\n",
    "            F.col(\"city\").alias(\"dest_city\"),\n",
    "            F.col(\"state\").alias(\"dest_state\"),\n",
    "            F.col(\"latitude\").alias(\"dest_latitude\"),\n",
    "            F.col(\"longitude\").alias(\"dest_longitude\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Join com aeroportos de origem e destino\n",
    "    df_joined = (\n",
    "        df_joined.join(\n",
    "            df_origin,\n",
    "            df_joined[origin_col] == F.col(\"origin_airport_iata_code\"),\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .join(\n",
    "            df_dest,\n",
    "            df_joined[dest_col] == F.col(\"dest_airport_iata_code\"),\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Mapeamento dos tipos\n",
    "    schema_casts = {\n",
    "        \"flight_id\": \"bigint\",\n",
    "        \"flight_year\": \"smallint\",\n",
    "        \"flight_month\": \"smallint\",\n",
    "        \"flight_day\": \"smallint\",\n",
    "        \"flight_day_of_week\": \"smallint\",\n",
    "        \"flight_date\": \"date\",\n",
    "\n",
    "        \"airline_iata_code\": \"string\",\n",
    "        \"airline_name\": \"string\",\n",
    "\n",
    "        \"flight_number\": \"int\",\n",
    "        \"tail_number\": \"string\",\n",
    "\n",
    "        \"origin_airport_iata_code\": \"string\",\n",
    "        \"origin_airport_name\": \"string\",\n",
    "        \"origin_city\": \"string\",\n",
    "        \"origin_state\": \"string\",\n",
    "        \"origin_latitude\": \"double\",\n",
    "        \"origin_longitude\": \"double\",\n",
    "\n",
    "        \"dest_airport_iata_code\": \"string\",\n",
    "        \"dest_airport_name\": \"string\",\n",
    "        \"dest_city\": \"string\",\n",
    "        \"dest_state\": \"string\",\n",
    "        \"dest_latitude\": \"double\",\n",
    "        \"dest_longitude\": \"double\",\n",
    "\n",
    "        \"scheduled_departure\": \"timestamp\",\n",
    "        \"departure_time\": \"timestamp\",\n",
    "        \"scheduled_arrival\": \"timestamp\",\n",
    "        \"arrival_time\": \"timestamp\",\n",
    "        \"wheels_off\": \"timestamp\",\n",
    "        \"wheels_on\": \"timestamp\",\n",
    "\n",
    "        \"departure_delay\": \"double\",\n",
    "        \"arrival_delay\": \"double\",\n",
    "        \"taxi_out\": \"double\",\n",
    "        \"taxi_in\": \"double\",\n",
    "        \"air_time\": \"double\",\n",
    "        \"elapsed_time\": \"double\",\n",
    "        \"scheduled_time\": \"double\",\n",
    "        \"distance\": \"double\",\n",
    "\n",
    "        \"is_overnight_flight\": \"boolean\",\n",
    "\n",
    "        \"air_system_delay\": \"double\",\n",
    "        \"security_delay\": \"double\",\n",
    "        \"airline_delay\": \"double\",\n",
    "        \"late_aircraft_delay\": \"double\",\n",
    "        \"weather_delay\": \"double\",\n",
    "    }\n",
    "\n",
    "    for col_name, spark_type in schema_casts.items():\n",
    "        if col_name in df_joined.columns:\n",
    "            df_joined = df_joined.withColumn(col_name, F.col(col_name).cast(spark_type))\n",
    "\n",
    "\n",
    "    # Seleção final conforme o ddl\n",
    "    final_df = df_joined.select(\n",
    "        F.monotonically_increasing_id().alias(\"flight_id\"),\n",
    "        \"flight_year\",\n",
    "        \"flight_month\",\n",
    "        \"flight_day\",\n",
    "        \"flight_day_of_week\",\n",
    "        \"flight_date\",\n",
    "        \"airline_iata_code\",\n",
    "        \"airline_name\",\n",
    "        \"flight_number\",\n",
    "        \"tail_number\",\n",
    "        \"origin_airport_iata_code\",\n",
    "        \"origin_airport_name\",\n",
    "        \"origin_city\",\n",
    "        \"origin_state\",\n",
    "        \"origin_latitude\",\n",
    "        \"origin_longitude\",\n",
    "        \"dest_airport_iata_code\",\n",
    "        \"dest_airport_name\",\n",
    "        \"dest_city\",\n",
    "        \"dest_state\",\n",
    "        \"dest_latitude\",\n",
    "        \"dest_longitude\",\n",
    "        \"scheduled_departure\",\n",
    "        \"departure_time\",\n",
    "        \"scheduled_arrival\",\n",
    "        \"arrival_time\",\n",
    "        \"wheels_off\",\n",
    "        \"wheels_on\",\n",
    "        \"departure_delay\",\n",
    "        \"arrival_delay\",\n",
    "        \"taxi_out\",\n",
    "        \"taxi_in\",\n",
    "        \"air_time\",\n",
    "        \"elapsed_time\",\n",
    "        \"scheduled_time\",\n",
    "        \"distance\",\n",
    "        \"air_system_delay\",\n",
    "        \"security_delay\",\n",
    "        \"airline_delay\",\n",
    "        \"late_aircraft_delay\",\n",
    "        \"weather_delay\",\n",
    "    )\n",
    "\n",
    "    log.info(\"[Refinement][Aggregate] Agregação concluída com sucesso.\")\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd81c0c6-f137-4e39-9a5a-b2d2d2dbafdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 23:08:35 [INFO] refinement.silver_aggregate | [Refinement][Aggregate] Iniciando job de agregação da camada Silver.\n",
      "2025-11-13 23:08:35 [INFO] file_io | [INFO] Partição selecionada: 2025-11-12\n",
      "2025-11-13 23:08:35 [INFO] refinement.silver_aggregate | [Refinement][Aggregate] Lendo datasets Silver (flights, airlines, airports).\n",
      "2025-11-13 23:08:38 [INFO] refinement.silver_aggregate | [Refinement][Aggregate] Iniciando agregação dos datasets Silver.\n",
      "2025-11-13 23:08:39 [INFO] refinement.silver_aggregate | [Refinement][Aggregate] Agregação concluída com sucesso.\n",
      "2025-11-13 23:08:39 [INFO] quality_gates.silver_aggregated | [Quality][Aggregate] Iniciando validações do dataset agregado.\n",
      "2025-11-13 23:08:42 [INFO] quality_gates.silver_aggregated | [Quality][Aggregate]      _check_row_count_not_empty: OK\n",
      "2025-11-13 23:08:51 [INFO] quality_gates.silver_aggregated | [Quality][Aggregate]     _check_unique_primary_key: OK\n",
      "2025-11-13 23:08:59 [INFO] quality_gates.silver_aggregated | [Quality][Aggregate]      _check_no_null_in_dimensions: OK\n",
      "2025-11-13 23:09:00 [INFO] quality_gates.silver_aggregated | [Quality][Aggregate]      _check_positive_distance: OK\n",
      "2025-11-13 23:09:02 [INFO] quality_gates.silver_aggregated | [Quality][Aggregate]      _check_departure_before_arrival: OK\n",
      "2025-11-13 23:09:04 [INFO] quality_gates.silver_aggregated | [Quality][Aggregate]      _check_origin_dest_different: OK\n",
      "2025-11-13 23:09:04 [INFO] quality_gates.silver_aggregated | [Quality][Aggregate] Validações concluídas.\n",
      "2025-11-13 23:10:15 [INFO] refinement.silver_aggregate | [Refinement][Aggregate] Dataset agregado salvo em: /opt/airflow/data-layer/silver/2025-11-12/PARQUET/flights_aggregated.parquet\n",
      "2025-11-13 23:10:15 [INFO] refinement.silver_aggregate | [Refinement][Aggregate] Job de agregação encerrado.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    log.info(\"[Refinement][Aggregate] Iniciando job de agregação da camada Silver.\")\n",
    "\n",
    "    # Encontra partição de entrada\n",
    "    source_partition: str = find_partition(\n",
    "        base_path=silver_path,\n",
    "        mode=run_mode,\n",
    "        date_str=run_date,\n",
    "    )\n",
    "    base_dir: Path = Path(silver_path) / source_partition / \"PARQUET\"\n",
    "\n",
    "    flights_path: Path  = base_dir / \"flights_pre_join.parquet\"\n",
    "    airlines_path: Path = base_dir / \"airlines.parquet\"\n",
    "    airports_path: Path = base_dir / \"airports.parquet\"\n",
    "\n",
    "    # Verifica existência dos arquivos necessários\n",
    "    for required_file in [flights_path, airlines_path, airports_path]:\n",
    "        if not required_file.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"[Refinement][Aggregate][ERROR] Arquivo esperado não encontrado: {required_file}\"\n",
    "            )\n",
    "\n",
    "    # Leitura dos datasets\n",
    "    log.info(\"[Refinement][Aggregate] Lendo datasets Silver (flights, airlines, airports).\")\n",
    "\n",
    "    df_flights  = spark.read.parquet(str(flights_path))\n",
    "    df_airlines = spark.read.parquet(str(airlines_path))\n",
    "    df_airports = spark.read.parquet(str(airports_path))\n",
    "\n",
    "    # Construção do DataFrame agregado\n",
    "    aggregated_df: DataFrame = create_aggregated_flights_df(\n",
    "        flights_silver_df=df_flights,\n",
    "        airlines_silver_df=df_airlines,\n",
    "        airports_silver_df=df_airports,\n",
    "    )\n",
    "\n",
    "    # Filtra registros inválidos de aeroportos\n",
    "    aggregated_df = aggregated_df.filter(\n",
    "        F.col(\"origin_airport_iata_code\").isNotNull()\n",
    "        & F.col(\"dest_airport_iata_code\").isNotNull()\n",
    "    )\n",
    "\n",
    "    # Quality gates\n",
    "    run_quality_gates_silver_aggregated(aggregated_df)\n",
    "\n",
    "    # Escrita do arquivo final\n",
    "    output_path: Path = base_dir / \"flights_aggregated.parquet\"\n",
    "    aggregated_df.coalesce(1).write.mode(\"overwrite\").parquet(str(output_path))\n",
    "\n",
    "    log.info(f\"[Refinement][Aggregate] Dataset agregado salvo em: {output_path}\")\n",
    "\n",
    "    # Libera cache após uso\n",
    "    aggregated_df.unpersist()\n",
    "\n",
    "except Exception as e:\n",
    "    log.exception(f\"[Refinement][Aggregate][ERROR] Falha na execução do job: {e}\")\n",
    "    raise\n",
    "\n",
    "finally:\n",
    "    log.info(\"[Refinement][Aggregate] Job de agregação encerrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb12e41b-9bad-4370-a5fd-a5b629ac376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # Comentar essa linha se estiver em debug ou se quiser rodar a célula.\n",
    "\n",
    "aggregated_df.printSchema()\n",
    "\n",
    "aggregated_df.limit(5).show(truncate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e2281f-3870-40ec-866d-b9536a4e8abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 23:10:20 [INFO] refinement.silver_aggregate | [Refinement][Aggregate] Sessão Spark finalizada.\n"
     ]
    }
   ],
   "source": [
    "# Encerra a sessão Spark\n",
    "spark.stop()\n",
    "log.info(\"[Refinement][Aggregate] Sessão Spark finalizada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda81b31-33c3-49db-92bc-d5231541fd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
